{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Annotations to Features\n",
    "\n",
    "This Python notebook describes the process of the three files:\n",
    "\n",
    "- `users_infected_diffusion.graphml` with the users their attributes, and the diffusion;\n",
    "\n",
    "- `tweets.csv` with the tweets and their respective users;\n",
    "\n",
    "- `users_to_annotate.csv` a csv file with the 5071 users to be annotated.\n",
    "\n",
    "- `annotated.csv` a csv file with the results in the annotation.\n",
    "\n",
    "- `created_at.csv` a csv file with the creation date for the annotated users. This was collected after the main data collection, due to a bug in the data collection script (which has been fixed).\n",
    "\n",
    "Into the following files:\n",
    "\n",
    "- `users_all_neigh.csv` a csv file with the features extracted for the $100000$ users.\n",
    "\n",
    "- `users_all_neigh_anon.csv` an anonymous version of the previous file.\n",
    "\n",
    "- A set of files to be used by GraphSage:\n",
    "\n",
    "    - `sw-G.json` -- A networkx-specified json file describing the input graph. Nodes have 'val' and 'test' attributes specifying if they are a part of the validation and test sets, respectively.\n",
    "    - `sw-id_map.json` -- A json-stored dictionary mapping the graph node ids to consecutive integers.\n",
    "    - `sw-class_map.json` -- A json-stored dictionary mapping the graph node ids to classes.\n",
    "    - `sw-feats.npy` --- A numpy-stored array of node features; ordering given by id_map.json. Can be omitted and only identity features will be used.\n",
    "    \n",
    "We begin extracting the median and average time between tweets for each user using the `tweets.csv` file:\n",
    "\n",
    "`tweets.csv` $\\rightarrow$ `time_diff.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets = pd.read_csv(\"../data/tweets.csv\")\n",
    "tweets.sort_values(by=[\"user_id\", \"tweet_creation\"], ascending=True, inplace=True)\n",
    "tweets[\"time_diff\"] = tweets.groupby(\"user_id\", sort=False).tweet_creation.diff()\n",
    "time_diff_series_mean = tweets.groupby(\"user_id\", sort=False).time_diff.mean()\n",
    "time_diff_series_median = tweets.groupby(\"user_id\", sort=False).time_diff.median()\n",
    "time_diff = time_diff_series_mean.to_frame()\n",
    "time_diff[\"time_diff_median\"] = time_diff_series_median\n",
    "time_diff.to_csv(\"../data/time_diff.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use this time difference, the diffusion graph, and the annotations. We link these values, and calculate centrality measures for the graph, such as betweenness, eigenvector, in degree and out degree.\n",
    "\n",
    "We also set a flag for the **neighbors** of the users who are hateful or normal.\n",
    "\n",
    "`time_diff.csv` `users_infected_diffusion.graphml` `annotated.csv` $\\rightarrow$ `users_hate.graphml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Read annotated users\n",
    "\n",
    "f = open(\"../data/annotated.csv\", \"r\")\n",
    "csv_writer = csv.DictReader(f)\n",
    "\n",
    "set_users = dict()\n",
    "\n",
    "for line in csv_writer:\n",
    "    if line[\"hate\"] == '1':\n",
    "        set_users[line[\"user_id\"]] = 1\n",
    "    elif line[\"hate\"] == \"0\":\n",
    "        set_users[line[\"user_id\"]] = 0\n",
    "f.close()\n",
    "\n",
    "# Read intervals between tweets\n",
    "\n",
    "f = open(\"../data/time_diff.csv\", \"r\")\n",
    "csv_writer = csv.DictReader(f)\n",
    "\n",
    "users_interval_median = dict()\n",
    "users_interval_average = dict()\n",
    "\n",
    "for line in csv_writer:\n",
    "    users_interval_median[line[\"user_id\"]] = line[\"time_diff_median\"]\n",
    "    users_interval_average[line[\"user_id\"]] = line[\"time_diff\"]\n",
    "\n",
    "# Set hate attributes\n",
    "\n",
    "nx_graph = nx.read_graphml(\"../data/users_infected_diffusion.graphml\")\n",
    "nx.set_node_attributes(nx_graph, name=\"hate\", values=-1)\n",
    "nx.set_node_attributes(nx_graph, name=\"hate\", values=set_users)\n",
    "\n",
    "# Set hateful and normal neighbors attribute\n",
    "\n",
    "nodes = nx_graph.nodes(data='hate')\n",
    "\n",
    "hateful_neighbors = dict()\n",
    "normal_neighbors = dict()\n",
    "\n",
    "for i in nodes:\n",
    "    if i[1] == 1:  # hateful node\n",
    "        for j in nx_graph.neighbors(i[0]):\n",
    "            hateful_neighbors[j] = True\n",
    "    if i[1] == 0:\n",
    "        for j in nx_graph.neighbors(i[0]):\n",
    "            normal_neighbors[j] = True\n",
    "\n",
    "nx.set_node_attributes(nx_graph, name=\"hateful_neighbors\", values=False)\n",
    "nx.set_node_attributes(nx_graph, name=\"hateful_neighbors\", values=hateful_neighbors)\n",
    "nx.set_node_attributes(nx_graph, name=\"normal_neighbors\", values=False)\n",
    "nx.set_node_attributes(nx_graph, name=\"normal_neighbors\", values=normal_neighbors)\n",
    "\n",
    "# Set median and average interval attributes\n",
    "\n",
    "nx.set_node_attributes(nx_graph, name=\"median_interval\", values=users_interval_median)\n",
    "nx.set_node_attributes(nx_graph, name=\"average_interval\", values=users_interval_average)\n",
    "\n",
    "# Set node network-based attributes, such as betweenness and eigenvector\n",
    "vt = time.time()\n",
    "betweenness = nx.betweenness_centrality(nx_graph, k=16258, normalized=False)\n",
    "eigenvector = nx.eigenvector_centrality(nx_graph)\n",
    "in_degree = nx.in_degree_centrality(nx_graph)\n",
    "out_degree = nx.out_degree_centrality(nx_graph)\n",
    "\n",
    "nx.set_node_attributes(nx_graph, name=\"betweenness\", values=betweenness)\n",
    "nx.set_node_attributes(nx_graph, name=\"eigenvector\", values=eigenvector)\n",
    "nx.set_node_attributes(nx_graph, name=\"in_degree\", values=in_degree)\n",
    "nx.set_node_attributes(nx_graph, name=\"out_degree\", values=out_degree)\n",
    "\n",
    "nx.write_graphml(nx_graph, \"../data/users_hate.graphml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a csv file with users and these attributes:\n",
    "\n",
    "    user_id            - unique identifier of a user \n",
    "    hate               - hateful|normal|other\n",
    "    hate_neigh         - True|False\n",
    "    normal_neigh       - True|False\n",
    "    statuses_count     - number of statuses\n",
    "    followers_count    - number of followers\n",
    "    followees_count    - number of followees\n",
    "    favorites_count    - number of favorites\n",
    "    listed_count       - number of listed\n",
    "    median_int         - median interval between tweets\n",
    "    average_int        - average interval between tweets\n",
    "    betweenness        - centrality measure\n",
    "    eigenvector        - centrality measure\n",
    "    in_degree          - centrality measure\n",
    "    out_degree         - centrality measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "nx_graph = nx.read_graphml(\"../data/users_hate.graphml\")\n",
    "\n",
    "hate = nx.get_node_attributes(nx_graph, \"hate\")\n",
    "hate_n = nx.get_node_attributes(nx_graph, \"hateful_neighbors\")\n",
    "normal_n = nx.get_node_attributes(nx_graph, \"normal_neighbors\")\n",
    "betweenness = nx.get_node_attributes(nx_graph, \"betweenness\")\n",
    "eigenvector = nx.get_node_attributes(nx_graph, \"eigenvector\")\n",
    "in_degree = nx.get_node_attributes(nx_graph, \"in_degree\")\n",
    "out_degree = nx.get_node_attributes(nx_graph, \"out_degree\")\n",
    "statuses_count = nx.get_node_attributes(nx_graph, \"statuses_count\")\n",
    "followers_count = nx.get_node_attributes(nx_graph, \"followers_count\")\n",
    "followees_count = nx.get_node_attributes(nx_graph, \"followees_count\")\n",
    "favorites_count = nx.get_node_attributes(nx_graph, \"favorites_count\")\n",
    "listed_count = nx.get_node_attributes(nx_graph, \"listed_count\")\n",
    "median_interval = nx.get_node_attributes(nx_graph, \"median_interval\")\n",
    "average_interval = nx.get_node_attributes(nx_graph, \"average_interval\")\n",
    "\n",
    "users = []\n",
    "\n",
    "for user_id in hate.keys():\n",
    "    hateful = \"other\"\n",
    "\n",
    "    if hate[user_id] == 1:\n",
    "        hateful = \"hateful\"\n",
    "\n",
    "    elif hate[user_id] == 0:\n",
    "        hateful = \"normal\"\n",
    "\n",
    "    median_int = None if user_id not in median_interval else median_interval[user_id]\n",
    "\n",
    "    average_int = None if user_id not in average_interval else average_interval[user_id]\n",
    "\n",
    "    users.append((user_id, hateful, hate_n[user_id], normal_n[user_id],  # General Stuff\n",
    "                  statuses_count[user_id], followers_count[user_id], followees_count[user_id],\n",
    "                  favorites_count[user_id], listed_count[user_id], median_int,  average_int,  # Numeric attributes\n",
    "                  betweenness[user_id], eigenvector[user_id],  # Network Attributes\n",
    "                  in_degree[user_id], out_degree[user_id]))\n",
    "\n",
    "columns = [\"user_id\", \"hate\", \"hate_neigh\", \"normal_neigh\", \"statuses_count\", \"followers_count\", \"followees_count\",\n",
    "           \"favorites_count\", \"listed_count\", \"median_int\", \"average_int\",\n",
    "           \"betweenness\", \"eigenvector\", \"in_degree\", \"out_degree\"]\n",
    "\n",
    "df = pd.DataFrame.from_records(users, columns=columns)\n",
    "df.to_csv(\"../data/users_attributes.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abusive_users_osn",
   "language": "python",
   "name": "abusive_users_osn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
